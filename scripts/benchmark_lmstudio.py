#!/usr/bin/env python3
"""
LM Studio API Benchmark Script
æµ‹è¯• LM Studio æœåŠ¡å™¨æ€§èƒ½
"""

import json
import time
import requests
from datetime import datetime

# é…ç½®
API_BASE = "http://localhost:1234/v1"
MODEL_NAME = "qwen3-coder-next"

# æµ‹è¯•ç”¨ä¾‹
TESTS = {
    "short": {
        "name": "çŸ­æ–‡æœ¬ç”Ÿæˆ",
        "prompt": "è¯·ç”¨ä¸€å¥è¯è§£é‡Šé‡å­è®¡ç®—",
        "max_tokens": 100
    },
    "medium": {
        "name": "ä»£ç ç”Ÿæˆ",
        "prompt": "å†™ä¸€ä¸ªPythonå¿«é€Ÿæ’åºç®—æ³•ï¼ŒåŒ…å«å®Œæ•´æ³¨é‡Š",
        "max_tokens": 500
    },
    "long": {
        "name": "é•¿æ–‡æœ¬ç”Ÿæˆ",
        "prompt": "è¯¦ç»†è§£é‡Šæ·±åº¦å­¦ä¹ çš„åå‘ä¼ æ’­ç®—æ³•ï¼ŒåŒ…æ‹¬æ•°å­¦æ¨å¯¼è¿‡ç¨‹",
        "max_tokens": 2000
    },
    "reasoning": {
        "name": "æ¨ç†èƒ½åŠ›",
        "prompt": "æœ‰5ä¸ªäººæ’é˜Ÿï¼Œå·²çŸ¥ï¼šAä¸åœ¨ç¬¬ä¸€ä½ï¼ŒBåœ¨Cå‰é¢ï¼ŒDç´§æŒ¨ç€Eï¼ŒAåœ¨Dåé¢ã€‚è¯·æ¨ç†å‡ºä»–ä»¬çš„æ’åˆ—é¡ºåºã€‚",
        "max_tokens": 500
    },
    "instruction": {
        "name": "æŒ‡ä»¤è·Ÿéš",
        "prompt": "è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š\n1. åˆ—å‡º3ç§å¸¸è§çš„æ’åºç®—æ³•\n2. ä¸ºæ¯ç§ç®—æ³•å†™å‡ºæ—¶é—´å¤æ‚åº¦\n3. ç”¨ä¸€å¥è¯æ€»ç»“å®ƒä»¬çš„é€‚ç”¨åœºæ™¯",
        "max_tokens": 400
    }
}


def run_test(test_name, test_config):
    """è¿è¡Œå•ä¸ªæµ‹è¯•"""
    print(f"\n{'='*60}")
    print(f"æµ‹è¯•: {test_config['name']}")
    print(f"{'='*60}")

    # å‡†å¤‡è¯·æ±‚
    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "user", "content": test_config["prompt"]}
        ],
        "max_tokens": test_config["max_tokens"],
        "temperature": 0.7
    }

    # å‘é€è¯·æ±‚å¹¶è®¡æ—¶
    start_time = time.time()

    try:
        response = requests.post(
            f"{API_BASE}/chat/completions",
            json=payload,
            headers={"Content-Type": "application/json"},
            timeout=300
        )
        response.raise_for_status()

        end_time = time.time()
        total_time = end_time - start_time

        # è§£æå“åº”
        result = response.json()

        # æå–æ•°æ®
        content = result["choices"][0]["message"]["content"]
        usage = result.get("usage", {})
        prompt_tokens = usage.get("prompt_tokens", 0)
        completion_tokens = usage.get("completion_tokens", 0)

        # è®¡ç®—æŒ‡æ ‡
        # æ³¨æ„ï¼šLM Studio ä¸æä¾› TTFTï¼Œæˆ‘ä»¬ä¼°ç®—æ€»æ—¶é—´
        tps = completion_tokens / total_time if total_time > 0 else 0

        # æ˜¾ç¤ºç»“æœ
        print(f"âœ“ å®Œæˆ")
        print(f"  Prompt tokens: {prompt_tokens}")
        print(f"  Completion tokens: {completion_tokens}")
        print(f"  æ€»æ—¶é—´: {total_time:.2f}s")
        print(f"  TPS: {tps:.2f}")
        print(f"  å“åº”é¢„è§ˆ: {content[:100]}...")

        return {
            "test_name": test_name,
            "name": test_config["name"],
            "prompt": test_config["prompt"],
            "max_tokens": test_config["max_tokens"],
            "prompt_tokens": prompt_tokens,
            "completion_tokens": completion_tokens,
            "total_time": total_time,
            "tps": tps,
            "content": content,
            "success": True
        }

    except Exception as e:
        print(f"âœ— é”™è¯¯: {e}")
        return {
            "test_name": test_name,
            "name": test_config["name"],
            "error": str(e),
            "success": False
        }


def main():
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘         LM Studio Performance Benchmark                 â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print(f"\nAPI: {API_BASE}")
    print(f"æ¨¡å‹: {MODEL_NAME}")
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # æ£€æŸ¥æœåŠ¡å™¨
    print("\næ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€...")
    try:
        response = requests.get(f"{API_BASE}/models", timeout=5)
        response.raise_for_status()
        print("âœ“ æœåŠ¡å™¨è¿è¡Œæ­£å¸¸")
    except Exception as e:
        print(f"âœ— æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨: {e}")
        return

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    results = []
    for test_name, test_config in TESTS.items():
        result = run_test(test_name, test_config)
        results.append(result)
        time.sleep(2)  # é—´éš”2ç§’

    # ç»Ÿè®¡ç»“æœ
    print(f"\n{'='*60}")
    print("æµ‹è¯•æ€»ç»“")
    print(f"{'='*60}")

    successful_tests = [r for r in results if r.get("success")]

    if not successful_tests:
        print("æ‰€æœ‰æµ‹è¯•å¤±è´¥")
        return

    # è®¡ç®—å¹³å‡å€¼
    avg_tps = sum(r["tps"] for r in successful_tests) / len(successful_tests)
    max_tps = max(r["tps"] for r in successful_tests)
    min_tps = min(r["tps"] for r in successful_tests)
    total_tokens = sum(r["completion_tokens"] for r in successful_tests)
    total_time = sum(r["total_time"] for r in successful_tests)

    print(f"\né€šè¿‡æµ‹è¯•: {len(successful_tests)}/{len(results)}")
    print(f"æ€»tokens: {total_tokens}")
    print(f"æ€»æ—¶é—´: {total_time:.2f}s")
    print(f"å¹³å‡TPS: {avg_tps:.2f}")
    print(f"æœ€å¤§TPS: {max_tps:.2f}")
    print(f"æœ€å°TPS: {min_tps:.2f}")

    # è¯¦ç»†ç»“æœè¡¨æ ¼
    print(f"\n{'='*60}")
    print("è¯¦ç»†ç»“æœ")
    print(f"{'='*60}")
    print(f"{'æµ‹è¯•':<15} {'Tokens':<8} {'æ—¶é—´(s)':<10} {'TPS':<8}")
    print("-" * 60)

    for r in successful_tests:
        print(f"{r['name']:<15} {r['completion_tokens']:<8} "
              f"{r['total_time']:<10.2f} {r['tps']:<8.2f}")

    # ä¿å­˜ç»“æœ
    output_file = f"lmstudio-benchmark-{datetime.now().strftime('%Y%m%d-%H%M%S')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            "timestamp": datetime.now().isoformat(),
            "api_base": API_BASE,
            "model": MODEL_NAME,
            "summary": {
                "avg_tps": avg_tps,
                "max_tps": max_tps,
                "min_tps": min_tps,
                "total_tokens": total_tokens,
                "total_time": total_time
            },
            "results": results
        }, f, indent=2, ensure_ascii=False)

    print(f"\nâœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print("\nğŸ‰ æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    main()
