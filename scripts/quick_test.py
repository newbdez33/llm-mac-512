#!/usr/bin/env python3
"""
MLX MiniMax M2.1 å¿«é€Ÿæµ‹è¯•è„šæœ¬

å¿«é€ŸéªŒè¯MLXç¯å¢ƒå’Œæ¨¡å‹è¿è¡Œæ˜¯å¦æ­£å¸¸

ä½¿ç”¨æ–¹æ³•:
    python scripts/quick_test.py
    python scripts/quick_test.py --model mlx-community/MiniMax-M2.1-6bit
"""

import argparse
import time
import sys
from mlx_lm import load, generate
from mlx_lm.sample_utils import make_sampler


def parse_args():
    parser = argparse.ArgumentParser(description="MLX å¿«é€Ÿæµ‹è¯•")
    parser.add_argument(
        "--model",
        type=str,
        default="mlx-community/MiniMax-M2.1-4bit",
        help="æ¨¡å‹åç§°",
    )
    return parser.parse_args()


def test_import():
    """æµ‹è¯•å¯¼å…¥"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 1/4: æ£€æŸ¥ä¾èµ–")
    print("=" * 60)

    try:
        import mlx.core as mx
        print(f"âœ“ MLX version: {mx.__version__}")
    except Exception as e:
        print(f"âœ— MLXå¯¼å…¥å¤±è´¥: {e}")
        return False

    try:
        import mlx_lm
        print(f"âœ“ mlx-lm å·²å®‰è£…")
    except Exception as e:
        print(f"âœ— mlx-lmå¯¼å…¥å¤±è´¥: {e}")
        return False

    try:
        import mlx.core as mx
        if mx.metal.is_available():
            print(f"âœ“ Metal GPU å¯ç”¨")
        else:
            print(f"âš  Metal GPU ä¸å¯ç”¨")
    except:
        print(f"âš  æ— æ³•æ£€æŸ¥MetalçŠ¶æ€")

    return True


def test_model_load(model_name):
    """æµ‹è¯•æ¨¡å‹åŠ è½½"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2/4: åŠ è½½æ¨¡å‹")
    print("=" * 60)
    print(f"æ¨¡å‹: {model_name}")
    print("é¦–æ¬¡è¿è¡Œä¼šä¸‹è½½æ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…...\n")

    try:
        start_time = time.time()
        model, tokenizer = load(model_name)
        load_time = time.time() - start_time

        print(f"âœ“ æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        print(f"  åŠ è½½æ—¶é—´: {load_time:.2f} ç§’")

        return model, tokenizer

    except Exception as e:
        print(f"âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None, None


def test_generation(model, tokenizer):
    """æµ‹è¯•ç”Ÿæˆ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3/4: æ–‡æœ¬ç”Ÿæˆ")
    print("=" * 60)

    test_prompt = "è¯·ç”¨ä¸€å¥è¯è§£é‡Šäººå·¥æ™ºèƒ½"
    print(f"Prompt: {test_prompt}\n")

    try:
        start_time = time.time()
        sampler = make_sampler(temp=0.7)

        response = generate(
            model,
            tokenizer,
            prompt=test_prompt,
            max_tokens=100,
            sampler=sampler,
            verbose=False
        )

        gen_time = time.time() - start_time
        tokens = len(tokenizer.encode(response))
        tps = tokens / gen_time if gen_time > 0 else 0

        print(f"Response:\n{response}\n")
        print(f"âœ“ ç”ŸæˆæˆåŠŸï¼")
        print(f"  ç”Ÿæˆtokens: {tokens}")
        print(f"  ç”¨æ—¶: {gen_time:.2f} ç§’")
        print(f"  é€Ÿåº¦: {tps:.2f} tokens/ç§’")

        return True, tps

    except Exception as e:
        print(f"âœ— ç”Ÿæˆå¤±è´¥: {e}")
        return False, 0


def test_performance(model, tokenizer):
    """æµ‹è¯•æ€§èƒ½"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 4/4: æ€§èƒ½æµ‹è¯•")
    print("=" * 60)

    test_cases = [
        ("çŸ­æ–‡æœ¬", "ä»€ä¹ˆæ˜¯é‡å­è®¡ç®—ï¼Ÿ", 50),
        ("ä¸­æ–‡æœ¬", "å†™ä¸€ä¸ªPythonå†’æ³¡æ’åº", 200),
    ]

    results = []
    sampler = make_sampler(temp=0.7)

    for name, prompt, max_tokens in test_cases:
        print(f"\n{name} ({max_tokens} tokens)...")

        try:
            start_time = time.time()
            response = generate(
                model,
                tokenizer,
                prompt=prompt,
                max_tokens=max_tokens,
                sampler=sampler,
                verbose=False
            )
            gen_time = time.time() - start_time
            tokens = len(tokenizer.encode(response))
            tps = tokens / gen_time if gen_time > 0 else 0

            print(f"  âœ“ {tokens} tokens | {gen_time:.2f}s | {tps:.2f} TPS")
            results.append(tps)

        except Exception as e:
            print(f"  âœ— å¤±è´¥: {e}")
            results.append(0)

    if results:
        avg_tps = sum(results) / len(results)
        print(f"\nå¹³å‡æ€§èƒ½: {avg_tps:.2f} tokens/ç§’")
        return avg_tps
    else:
        return 0


def main():
    args = parse_args()

    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              MLX MiniMax M2.1 å¿«é€Ÿæµ‹è¯•                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

    # æµ‹è¯•1: å¯¼å…¥
    if not test_import():
        print("\nâœ— ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·å…ˆå®‰è£…ä¾èµ–:")
        print("  pip install mlx mlx-lm")
        sys.exit(1)

    # æµ‹è¯•2: åŠ è½½æ¨¡å‹
    model, tokenizer = test_model_load(args.model)
    if model is None:
        print("\nâœ— æ¨¡å‹åŠ è½½å¤±è´¥")
        sys.exit(1)

    # æµ‹è¯•3: ç”Ÿæˆ
    success, tps = test_generation(model, tokenizer)
    if not success:
        print("\nâœ— ç”Ÿæˆæµ‹è¯•å¤±è´¥")
        sys.exit(1)

    # æµ‹è¯•4: æ€§èƒ½
    avg_tps = test_performance(model, tokenizer)

    # æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    print(f"âœ“ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    print(f"âœ“ æ¨¡å‹: {args.model}")
    print(f"âœ“ å¹³å‡æ€§èƒ½: {avg_tps:.2f} tokens/ç§’")

    # æ€§èƒ½è¯„ä¼°
    print("\næ€§èƒ½è¯„ä¼°:")
    if avg_tps > 40:
        print("  ğŸš€ ä¼˜ç§€ï¼æ¥è¿‘æˆ–è¶…è¿‡é¢„æœŸæ€§èƒ½")
    elif avg_tps > 30:
        print("  âœ“ è‰¯å¥½ï¼æ€§èƒ½åœ¨å¯æ¥å—èŒƒå›´å†…")
    elif avg_tps > 20:
        print("  âš  ä¸€èˆ¬ï¼Œå¯èƒ½éœ€è¦ä¼˜åŒ–ï¼ˆæ£€æŸ¥VRAMè®¾ç½®ï¼‰")
    else:
        print("  âš  æ€§èƒ½è¾ƒä½ï¼Œå»ºè®®:")
        print("     - ä½¿ç”¨4-bitæ¨¡å‹")
        print("     - ä¼˜åŒ–VRAMé™åˆ¶")
        print("     - å…³é—­å…¶ä»–åº”ç”¨")

    print("\nâœ“ MLXç¯å¢ƒæ­£å¸¸ï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨ï¼")
    print("\nä¸‹ä¸€æ­¥:")
    print("  â€¢ äº¤äº’å¼å¯¹è¯: python scripts/chat_mlx.py")
    print("  â€¢ æ€§èƒ½æµ‹è¯•: python scripts/benchmark_mlx.py --model {args.model}")
    print("  â€¢ æŸ¥çœ‹æ–‡æ¡£: docs/mlx-local-setup.md")


if __name__ == "__main__":
    main()
